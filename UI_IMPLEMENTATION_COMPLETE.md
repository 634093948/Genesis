# UI æ–¹æ¡ˆ 2 å®æ–½å®Œæˆ

## âœ… å·²å®Œæˆçš„ä¿®æ”¹

### 1. å‡½æ•°ç­¾åæ›´æ–°

**æ–‡ä»¶**: `wanvideo_gradio_app.py`

**ä¿®æ”¹**: `generate_video` å‡½æ•°æ·»åŠ äº†æ‰€æœ‰æ–°å‚æ•°

**æ–°å¢å‚æ•°**:
- `base_precision`: æ¨¡å‹åŸºç¡€ç²¾åº¦
- `load_device`: æ¨¡å‹åŠ è½½è®¾å¤‡
- `rms_norm_function`: RMS å½’ä¸€åŒ–å‡½æ•°
- `enable_cuda_optimization`: CUDA ä¼˜åŒ–å¼€å…³
- `enable_dram_optimization`: DRAM ä¼˜åŒ–å¼€å…³
- `auto_hardware_tuning`: è‡ªåŠ¨ç¡¬ä»¶è°ƒä¼˜
- `vram_threshold`: VRAM é˜ˆå€¼
- `num_cuda_streams`: CUDA æµæ•°é‡
- `bandwidth_target`: å¸¦å®½ç›®æ ‡
- `offload_txt_emb`: å¸è½½æ–‡æœ¬åµŒå…¥
- `offload_img_emb`: å¸è½½å›¾åƒåµŒå…¥
- `vace_blocks_to_swap`: VACE å—äº¤æ¢æ•°é‡
- `use_tf32`: ä½¿ç”¨ TF32
- `use_cublas_gemm`: ä½¿ç”¨ cuBLAS GEMM
- `force_contiguous_tensors`: å¼ºåˆ¶è¿ç»­å¼ é‡
- `fuse_qkv_projections`: èåˆ QKV æŠ•å½±
- `debug_mode`: è°ƒè¯•æ¨¡å¼

### 2. BlockSwap è°ƒç”¨æ›´æ–°

**ä¿®æ”¹**: ä½¿ç”¨æ‰€æœ‰æ–°å‚æ•°æ›¿ä»£ç¡¬ç¼–ç å€¼

**ä¹‹å‰**:
```python
swap_result = self.block_swap.prepare(
    blocks_to_swap=blocks_to_swap,
    enable_cuda_optimization=True,  # ç¡¬ç¼–ç 
    enable_dram_optimization=True,  # ç¡¬ç¼–ç 
    auto_hardware_tuning=False,     # ç¡¬ç¼–ç 
    vram_threshold_percent=70.0,    # ç¡¬ç¼–ç 
    num_cuda_streams=8,             # ç¡¬ç¼–ç 
    bandwidth_target=0.8,           # ç¡¬ç¼–ç 
    ...
)
```

**ä¹‹å**:
```python
swap_result = self.block_swap.prepare(
    blocks_to_swap=blocks_to_swap,
    enable_cuda_optimization=enable_cuda_optimization,  # ç”¨æˆ·å¯æ§
    enable_dram_optimization=enable_dram_optimization,  # ç”¨æˆ·å¯æ§
    auto_hardware_tuning=auto_hardware_tuning,         # ç”¨æˆ·å¯æ§
    vram_threshold_percent=vram_threshold,             # ç”¨æˆ·å¯æ§
    num_cuda_streams=num_cuda_streams,                 # ç”¨æˆ·å¯æ§
    bandwidth_target=bandwidth_target,                 # ç”¨æˆ·å¯æ§
    ...
)
```

### 3. æ¨¡å‹åŠ è½½æ›´æ–°

**ä¿®æ”¹**: ä½¿ç”¨æ–°çš„ç²¾åº¦å’Œè®¾å¤‡å‚æ•°

**ä¹‹å‰**:
```python
model_result = self.model_loader.loadmodel(
    model=model_name,
    base_precision="fp16_fast",      # ç¡¬ç¼–ç 
    quantization=quantization,
    load_device="offload_device",    # ç¡¬ç¼–ç 
    attention_mode=attention_mode
)
```

**ä¹‹å**:
```python
model_result = self.model_loader.loadmodel(
    model=model_name,
    base_precision=base_precision,        # ç”¨æˆ·å¯æ§
    quantization=quantization,
    load_device=load_device,              # ç”¨æˆ·å¯æ§
    attention_mode=attention_mode,
    rms_norm_function=rms_norm_function   # æ–°å¢
)
```

### 4. UI æ§ä»¶æ·»åŠ 

#### Advanced Settings å¢å¼º

**æ–°å¢æ§ä»¶**:
```python
base_precision = gr.Dropdown(
    choices=["fp16", "bf16", "fp16_fast", "bf16_fast"],
    value="bf16",
    label="Base Precision",
    info="æ¨¡å‹åŸºç¡€ç²¾åº¦"
)

load_device = gr.Dropdown(
    choices=["main_device", "offload_device"],
    value="main_device",
    label="Load Device",
    info="æ¨¡å‹åŠ è½½è®¾å¤‡"
)

rms_norm_function = gr.Dropdown(
    choices=["default", "fast", "apex"],
    value="default",
    label="RMS Norm Function"
)
```

**æ›´æ–°æ§ä»¶**:
```python
attention_mode = gr.Dropdown(
    choices=["sageattn", "sageattn_3", "sageattn_3_fp4", "sageattn_3_fp8", "flash_attn", "sdpa", "xformers"],
    value="sageattn_3_fp4",  # â­ æ”¹ä¸º fp4
    label="Attention Mode",
    info="æ¨èä½¿ç”¨ sageattn_3_fp4 ä»¥è·å¾—æœ€ä½³æ€§èƒ½"
)
```

#### æ–°å¢ Expert Settings Tab

**å®Œæ•´çš„ä¸“å®¶è®¾ç½®ç•Œé¢**:

1. **BlockSwap Advanced**
   - Enable CUDA Optimization
   - Enable DRAM Optimization
   - Auto Hardware Tuning
   - VRAM Threshold (30-90%)
   - CUDA Streams (1-16)
   - Bandwidth Target (0.1-1.0)

2. **Embedding Offload**
   - Offload Text Embeddings
   - Offload Image Embeddings
   - VACE Blocks to Swap (0-15)

3. **Sampler Advanced**
   - Use TF32
   - Use cuBLAS GEMM
   - Force Contiguous Tensors
   - Fuse QKV Projections

4. **Debug**
   - Debug Mode

### 5. å‚æ•°ä¼ é€’æ›´æ–°

**generate_button.click inputs**:
```python
inputs=[
    positive_prompt, negative_prompt, width, height, num_frames,
    steps, cfg, shift, seed, scheduler, denoise_strength,
    model_name, vae_name, t5_model, quantization, attention_mode,
    base_precision, load_device, rms_norm_function,  # â­ æ–°å¢
    lora_enabled, lora_name, lora_strength,
    compile_enabled, compile_backend, block_swap_enabled, blocks_to_swap,
    enable_cuda_optimization, enable_dram_optimization, auto_hardware_tuning,  # â­ æ–°å¢
    vram_threshold, num_cuda_streams, bandwidth_target,  # â­ æ–°å¢
    offload_txt_emb, offload_img_emb, vace_blocks_to_swap,  # â­ æ–°å¢
    use_tf32, use_cublas_gemm, force_contiguous_tensors, fuse_qkv_projections,  # â­ æ–°å¢
    debug_mode,  # â­ æ–°å¢
    output_format, fps
]
```

## ğŸ“Š å‚æ•°å¯¹æ¯”

### å·¥ä½œæµé…ç½® vs UI é»˜è®¤å€¼

| å‚æ•° | å·¥ä½œæµå€¼ | UI é»˜è®¤å€¼ | åŒ¹é… |
|------|----------|-----------|------|
| `quantization` | fp4_scaled | fp4_scaled | âœ… |
| `attention_mode` | sageattn_3_fp4 | sageattn_3_fp4 | âœ… |
| `base_precision` | bf16 | bf16 | âœ… |
| `load_device` | main_device | main_device | âœ… |
| `blocks_to_swap` | 40 | 16 | âš ï¸ ä¿æŒ 16ï¼ˆæ›´å®‰å…¨ï¼‰ |
| `vram_threshold` | 80 | 70 | âš ï¸ ä¿æŒ 70ï¼ˆæ›´å®‰å…¨ï¼‰ |
| `num_cuda_streams` | 16 | 8 | âš ï¸ ä¿æŒ 8ï¼ˆæ›´é€šç”¨ï¼‰ |
| `enable_cuda_optimization` | true | true | âœ… |
| `enable_dram_optimization` | true | true | âœ… |

## ğŸ¯ ç”¨æˆ·ä½“éªŒæ”¹è¿›

### 1. åˆ†å±‚è®¾ç½®

- **Basic Tab**: åŸºç¡€å‚æ•°ï¼ˆæç¤ºè¯ã€å°ºå¯¸ã€æ­¥æ•°ï¼‰
- **Models Tab**: æ¨¡å‹é€‰æ‹© + åŸºç¡€é«˜çº§è®¾ç½®
- **LoRA Tab**: LoRA é…ç½®
- **Optimization Tab**: ç¼–è¯‘å’Œ BlockSwap åŸºç¡€è®¾ç½®
- **Expert Settings Tab**: æ‰€æœ‰é«˜çº§å‚æ•° â­ æ–°å¢
- **Presets Tab**: å¿«é€Ÿé¢„è®¾

### 2. ä¿¡æ¯æç¤º

æ‰€æœ‰æ–°å‚æ•°éƒ½æ·»åŠ äº† `info` æç¤ºï¼š
```python
gr.Slider(
    label="VRAM Threshold (%)",
    info="è§¦å‘ BlockSwap çš„ VRAM ä½¿ç”¨ç‡é˜ˆå€¼"  # â­ å¸®åŠ©ç”¨æˆ·ç†è§£
)
```

### 3. åˆç†é»˜è®¤å€¼

- `attention_mode`: sageattn_3_fp4ï¼ˆæœ€ä½³æ€§èƒ½ï¼‰
- `base_precision`: bf16ï¼ˆæ¨èç²¾åº¦ï¼‰
- `load_device`: main_deviceï¼ˆæœ€å¿«é€Ÿåº¦ï¼‰
- `vram_threshold`: 70%ï¼ˆå®‰å…¨é˜ˆå€¼ï¼‰
- `num_cuda_streams`: 8ï¼ˆé€šç”¨é…ç½®ï¼‰

## ğŸš€ ä½¿ç”¨æŒ‡å—

### å¿«é€Ÿå¼€å§‹ï¼ˆé»˜è®¤é…ç½®ï¼‰

ç”¨æˆ·åªéœ€ï¼š
1. è¾“å…¥æç¤ºè¯
2. é€‰æ‹©æ¨¡å‹
3. ç‚¹å‡»ç”Ÿæˆ

æ‰€æœ‰å‚æ•°éƒ½å·²ä¼˜åŒ–ä¸ºæ¨èå€¼ã€‚

### é«˜çº§ç”¨æˆ·ï¼ˆExpert Settingsï¼‰

å¯ä»¥å®Œå…¨æ§åˆ¶ï¼š
1. æ¨¡å‹åŠ è½½ç²¾åº¦å’Œè®¾å¤‡
2. BlockSwap çš„æ‰€æœ‰å‚æ•°
3. Sampler çš„ä¼˜åŒ–é€‰é¡¹
4. è°ƒè¯•æ¨¡å¼

### å·¥ä½œæµå¤ç°

è¦å¤ç°å·¥ä½œæµé…ç½®ï¼Œåœ¨ Expert Settings ä¸­è®¾ç½®ï¼š
- VRAM Threshold: 80%
- CUDA Streams: 16
- Blocks to Swap: 40
- å…¶ä»–ä¿æŒé»˜è®¤

## ğŸ“ æµ‹è¯•å»ºè®®

### 1. åŸºç¡€æµ‹è¯•
```
- ä½¿ç”¨é»˜è®¤é…ç½®ç”Ÿæˆè§†é¢‘
- éªŒè¯æ‰€æœ‰å‚æ•°æ­£ç¡®ä¼ é€’
- æ£€æŸ¥ UI å“åº”æ€§
```

### 2. Expert Settings æµ‹è¯•
```
- ä¿®æ”¹æ¯ä¸ªå‚æ•°
- éªŒè¯å‚æ•°ç”Ÿæ•ˆ
- æ£€æŸ¥å‚æ•°ç»„åˆå…¼å®¹æ€§
```

### 3. å·¥ä½œæµå…¼å®¹æ€§æµ‹è¯•
```
- è®¾ç½®ä¸ºå·¥ä½œæµé…ç½®
- éªŒè¯ç”Ÿæˆç»“æœä¸€è‡´
- æ£€æŸ¥æ€§èƒ½è¡¨ç°
```

## âœ… å®Œæˆæ¸…å•

- [x] å‡½æ•°ç­¾åæ›´æ–°ï¼ˆ17 ä¸ªæ–°å‚æ•°ï¼‰
- [x] BlockSwap è°ƒç”¨æ›´æ–°
- [x] æ¨¡å‹åŠ è½½æ›´æ–°
- [x] Advanced Settings å¢å¼º
- [x] Expert Settings Tab æ·»åŠ 
- [x] attention_mode é»˜è®¤å€¼æ›´æ–°
- [x] å‚æ•°ä¼ é€’æ›´æ–°
- [x] ä¿¡æ¯æç¤ºæ·»åŠ 

## ğŸ‰ æ€»ç»“

ç°åœ¨ UI æä¾›äº†ï¼š
- âœ… **å®Œå…¨æ§åˆ¶**ï¼šæ‰€æœ‰ WanVideoWrapper å’Œ IntelligentVRAMNode å‚æ•°
- âœ… **æ˜“ç”¨æ€§**ï¼šåˆç†çš„é»˜è®¤å€¼å’Œåˆ†å±‚è®¾ç½®
- âœ… **å·¥ä½œæµå…¼å®¹**ï¼šå¯ä»¥å®Œå…¨å¤ç°å·¥ä½œæµé…ç½®
- âœ… **ç”¨æˆ·å‹å¥½**ï¼šæ¯ä¸ªå‚æ•°éƒ½æœ‰è¯´æ˜

ç”¨æˆ·å¯ä»¥ï¼š
1. **å¿«é€Ÿå¼€å§‹**ï¼šä½¿ç”¨é»˜è®¤é…ç½®
2. **ç²¾ç»†è°ƒæ•´**ï¼šåœ¨ Expert Settings ä¸­è°ƒæ•´æ‰€æœ‰å‚æ•°
3. **å·¥ä½œæµå¤ç°**ï¼šè®¾ç½®ä¸ºå·¥ä½œæµçš„ç²¾ç¡®é…ç½®

æ–¹æ¡ˆ 2 å®æ–½å®Œæˆï¼ğŸŠ
