#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Qwen Image UI Integration
Qwen Image UI é›†æˆåˆ°æ–‡ç”Ÿå›¾æ ‡ç­¾

Based on: custom_nodes/Comfyui/ComfyUI-QwenImageWrapper
Workflow: qwen3 edy.json (without image interrogation nodes)

Author: eddy
Date: 2025-11-16
"""

import sys
from pathlib import Path
import gradio as gr

# Add project root
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# Import Qwen pipeline
try:
    # Direct import to avoid circular dependencies
    import importlib.util
    qwen_file = project_root / "apps" / "sd_module" / "qwen_comfy_pipeline.py"
    spec = importlib.util.spec_from_file_location("qwen_comfy_pipeline", qwen_file)
    qwen_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(qwen_module)
    
    QwenComfyPipeline = qwen_module.QwenComfyPipeline
    get_available_models = qwen_module.get_available_models
    QWEN_AVAILABLE = qwen_module.QWEN_AVAILABLE
except Exception as e:
    print(f"Failed to import Qwen: {e}")
    QWEN_AVAILABLE = False


def _unique(seq):
    """Keep list order while removing duplicates"""
    seen = set()
    result = []
    for item in seq:
        if item in seen:
            continue
        seen.add(item)
        result.append(item)
    return result


def create_qwen_subtab():
    """Create Qwen Image UI as a subtab"""
    
    if not QWEN_AVAILABLE:
        gr.Markdown("""
        ## âš ï¸ Qwen Image ä¸å¯ç”¨
        
        Qwen Image èŠ‚ç‚¹æœªåŠ è½½ã€‚è¯·ç¡®ä¿:
        1. custom_nodes/Comfyui/ComfyUI-QwenImageWrapper æ–‡ä»¶å¤¹å­˜åœ¨
        2. ç›¸å…³ä¾èµ–å·²å®‰è£…
        
        æŸ¥çœ‹æ–‡æ¡£: docs/QWEN_IMAGE_GUIDE.md
        """)
        return
    
    # Create pipeline
    pipeline = QwenComfyPipeline()
    models = get_available_models()
    
    # Model choices
    unet_choices = _unique(models['unet'] + models['diffusion_models'])
    clip_choices = _unique(models.get('clip', []) + models.get('text_encoders', []))
    vae_choices = _unique(models['vae'])
    lora_choices = ["none"] + _unique(models.get('loras', []))
    
    # Sampler and scheduler options
    sampler_list = [
        "sa_solver", "euler", "euler_a", "heun", "dpm_2", "dpm_2_a",
        "lms", "dpm_fast", "dpm_adaptive", 
        "dpmpp_2s_a", "dpmpp_2m", "dpmpp_sde",
        "ddim", "ddpm", "uni_pc", "uni_pc_bh2"
    ]
    
    scheduler_list = ["beta", "normal", "karras", "exponential", "sgm_uniform", "simple", "ddim_uniform"]
    
    gr.Markdown("""
    # ğŸ¨ Qwen Image æ–‡ç”Ÿå›¾
    
    **é«˜è´¨é‡å›¾åƒç”Ÿæˆï¼Œä½¿ç”¨ Qwen Image æ¨¡å‹**
    """)
    
    with gr.Row():
        # Left column: Settings
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ”§ æ¨¡å‹è®¾ç½®")
            
            with gr.Accordion("æ¨¡å‹é€‰æ‹©", open=True):
                unet_model = gr.Dropdown(
                    label="UNET æ¨¡å‹",
                    choices=unet_choices,
                    value=unet_choices[0] if unet_choices else None
                )
                
                clip_model = gr.Dropdown(
                    label="CLIP æ¨¡å‹",
                    choices=clip_choices,
                    value=clip_choices[0] if clip_choices else None
                )
                
                vae_model = gr.Dropdown(
                    label="VAE æ¨¡å‹",
                    choices=vae_choices,
                    value=vae_choices[0] if vae_choices else None
                )
            
            gr.Markdown("### ğŸ“ æç¤ºè¯")
            
            prompt = gr.Textbox(
                label="æ­£å‘æç¤ºè¯",
                placeholder="æè¿°ä½ æƒ³ç”Ÿæˆçš„å›¾åƒ...",
                lines=4
            )
            
            negative_prompt = gr.Textbox(
                label="è´Ÿå‘æç¤ºè¯",
                placeholder="æè¿°ä½ ä¸æƒ³è¦çš„å†…å®¹...",
                lines=2
            )
            
            gr.Markdown("### âš™ï¸ ç”Ÿæˆå‚æ•°")
            
            with gr.Row():
                width = gr.Slider(
                    label="å®½åº¦",
                    minimum=256,
                    maximum=2048,
                    value=1328,
                    step=16
                )
                
                height = gr.Slider(
                    label="é«˜åº¦",
                    minimum=256,
                    maximum=2048,
                    value=1328,
                    step=16
                )
            
            with gr.Row():
                steps = gr.Slider(
                    label="é‡‡æ ·æ­¥æ•°",
                    minimum=1,
                    maximum=100,
                    value=8,
                    step=1
                )
                
                cfg = gr.Slider(
                    label="CFG Scale",
                    minimum=0.0,
                    maximum=20.0,
                    value=2.5,
                    step=0.1
                )
            
            with gr.Row():
                sampler = gr.Dropdown(
                    label="é‡‡æ ·å™¨",
                    choices=sampler_list,
                    value="sa_solver"
                )
                
                scheduler = gr.Dropdown(
                    label="è°ƒåº¦å™¨",
                    choices=scheduler_list,
                    value="beta"
                )
            
            seed = gr.Number(
                label="ç§å­ (-1 ä¸ºéšæœº)",
                value=-1,
                precision=0
            )
            
            quantization_dtype = gr.Dropdown(
                label="é‡åŒ–ç²¾åº¦",
                choices=["default", "fp8_e4m3fn", "fp8_e5m2", "fp16", "fp16_fast", "bf16", "bf16_fast"],
                value="fp16_fast",
                info="fp8=æœ€å¿«+50% VRAMèŠ‚çœ, bf16_fast=å¹³è¡¡2.5xé€Ÿåº¦, default=æ— é‡åŒ–"
            )
            
            with gr.Accordion("LoRA è®¾ç½®", open=False):
                with gr.Row():
                    lora_1_name = gr.Dropdown(
                        label="LoRA 1",
                        choices=lora_choices,
                        value="none"
                    )
                    lora_1_strength = gr.Slider(
                        label="å¼ºåº¦",
                        minimum=-10.0,
                        maximum=10.0,
                        value=1.0,
                        step=0.05
                    )
                
                with gr.Row():
                    lora_2_name = gr.Dropdown(
                        label="LoRA 2",
                        choices=lora_choices,
                        value="none"
                    )
                    lora_2_strength = gr.Slider(
                        label="å¼ºåº¦",
                        minimum=-10.0,
                        maximum=10.0,
                        value=0.0,
                        step=0.05
                    )
                
                with gr.Row():
                    lora_3_name = gr.Dropdown(
                        label="LoRA 3",
                        choices=lora_choices,
                        value="none"
                    )
                    lora_3_strength = gr.Slider(
                        label="å¼ºåº¦",
                        minimum=-10.0,
                        maximum=10.0,
                        value=0.0,
                        step=0.05
                    )
                
                with gr.Row():
                    lora_4_name = gr.Dropdown(
                        label="LoRA 4",
                        choices=lora_choices,
                        value="none"
                    )
                    lora_4_strength = gr.Slider(
                        label="å¼ºåº¦",
                        minimum=-10.0,
                        maximum=10.0,
                        value=0.0,
                        step=0.05
                    )
            
            with gr.Accordion("ä¼˜åŒ–è®¾ç½®", open=False):
                use_blockswap = gr.Checkbox(
                    label="å¯ç”¨ BlockSwap (30-60% VRAM èŠ‚çœ)",
                    value=True
                )
                
                with gr.Row():
                    blockswap_blocks = gr.Slider(
                        label="BlockSwap å—æ•°",
                        minimum=1,
                        maximum=50,
                        value=20,
                        step=1
                    )
                    
                    blockswap_model_size = gr.Dropdown(
                        label="æ¨¡å‹å¤§å°",
                        choices=["auto", "small", "medium", "large", "xl"],
                        value="auto"
                    )
                
                blockswap_use_recommended = gr.Checkbox(
                    label="ä½¿ç”¨æ¨èé…ç½®",
                    value=True
                )
                
                enable_matmul_optimization = gr.Checkbox(
                    label="å¯ç”¨çŸ©é˜µä¹˜æ³•ä¼˜åŒ– (1.5-2x åŠ é€Ÿ)",
                    value=True
                )
                
                use_torch_compile = gr.Checkbox(
                    label="å¯ç”¨ Torch Compile (20-60% åŠ é€Ÿï¼Œé¦–æ¬¡æ…¢)",
                    value=False
                )
                
                matmul_precision = gr.Dropdown(
                    label="çŸ©é˜µç²¾åº¦",
                    choices=["highest", "high", "medium"],
                    value="high"
                )
                
                use_autocast = gr.Checkbox(
                    label="å¯ç”¨æ··åˆç²¾åº¦ (30-50% åŠ é€Ÿ)",
                    value=False
                )
                
                autocast_dtype = gr.Dropdown(
                    label="Autocast ç±»å‹",
                    choices=["float16", "bfloat16"],
                    value="bfloat16"
                )
                
                use_channels_last = gr.Checkbox(
                    label="ä½¿ç”¨ Channels Last (10-20% åŠ é€Ÿ)",
                    value=False
                )
                
                enable_flash_attention = gr.Checkbox(
                    label="å¯ç”¨ Flash Attention (2-4x åŠ é€Ÿ)",
                    value=True
                )
                
                compile_mode = gr.Dropdown(
                    label="ç¼–è¯‘æ¨¡å¼",
                    choices=["default", "reduce-overhead", "max-autotune"],
                    value="default"
                )
                
                enable_kv_cache = gr.Checkbox(
                    label="å¯ç”¨ KV Cache",
                    value=True
                )
            
            generate_btn = gr.Button("ğŸ¨ ç”Ÿæˆå›¾åƒ", variant="primary", size="lg")
        
        # Right column: Output
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ–¼ï¸ ç”Ÿæˆç»“æœ")
            
            output_image = gr.Image(
                label="ç»“æœ",
                type="pil"
            )
            
            output_info = gr.Markdown(
                value="ç‚¹å‡»ç”Ÿæˆå¼€å§‹..."
            )
    
    # Event handlers
    def generate_wrapper(
        prompt, negative_prompt, unet_model, clip_model, vae_model,
        width, height, steps, cfg, sampler, scheduler, seed,
        quantization_dtype,
        lora_1_name, lora_1_strength,
        lora_2_name, lora_2_strength,
        lora_3_name, lora_3_strength,
        lora_4_name, lora_4_strength,
        use_blockswap, blockswap_blocks, blockswap_model_size, blockswap_use_recommended,
        enable_matmul_optimization, use_torch_compile, matmul_precision,
        use_autocast, autocast_dtype, use_channels_last,
        enable_flash_attention, compile_mode, enable_kv_cache,
        progress=gr.Progress()
    ):
        """Generate image wrapper"""
        try:
            if not QWEN_AVAILABLE:
                return None, "âŒ Qwen Image æ¨¡å—æœªåŠ è½½"
            
            if not prompt:
                return None, "âŒ è¯·è¾“å…¥æç¤ºè¯"
            
            progress(0, desc="ç”Ÿæˆä¸­...")
            
            # Generate
            images = pipeline.generate(
                prompt=prompt,
                negative_prompt=negative_prompt,
                unet_name=unet_model,
                clip_name=clip_model,
                vae_name=vae_model,
                width=int(width),
                height=int(height),
                steps=int(steps),
                cfg=cfg,
                sampler_name=sampler,
                scheduler=scheduler,
                seed=int(seed),
                quantization_dtype=quantization_dtype,
                lora_1_name=lora_1_name,
                lora_1_strength=lora_1_strength,
                lora_2_name=lora_2_name,
                lora_2_strength=lora_2_strength,
                lora_3_name=lora_3_name,
                lora_3_strength=lora_3_strength,
                lora_4_name=lora_4_name,
                lora_4_strength=lora_4_strength,
                use_blockswap=use_blockswap,
                blockswap_blocks=int(blockswap_blocks),
                blockswap_model_size=blockswap_model_size,
                blockswap_use_recommended=blockswap_use_recommended,
                enable_matmul_optimization=enable_matmul_optimization,
                use_torch_compile=use_torch_compile,
                matmul_precision=matmul_precision,
                use_autocast=use_autocast,
                autocast_dtype=autocast_dtype,
                use_channels_last=use_channels_last,
                enable_flash_attention=enable_flash_attention,
                compile_mode=compile_mode,
                enable_kv_cache=enable_kv_cache
            )
            
            if images:
                info = f"""
## âœ… ç”Ÿæˆå®Œæˆ!

**æç¤ºè¯:** {prompt[:100]}...

**å‚æ•°:**
- å°ºå¯¸: {width} x {height}
- æ­¥æ•°: {steps}
- CFG: {cfg}
- é‡‡æ ·å™¨: {sampler}
- è°ƒåº¦å™¨: {scheduler}
- ç§å­: {seed if seed >= 0 else 'éšæœº'}
- é‡åŒ–: {quantization_dtype}

**æ¨¡å‹:**
- UNET: {unet_model}
- CLIP: {clip_model}
- VAE: {vae_model}
"""
                return images[0] if images else None, info
            else:
                return None, "âŒ ç”Ÿæˆå¤±è´¥ï¼ŒæŸ¥çœ‹æ§åˆ¶å°äº†è§£è¯¦æƒ…"
                
        except Exception as e:
            import traceback
            traceback.print_exc()
            return None, f"âŒ é”™è¯¯: {e}"
    
    # Connect events
    generate_btn.click(
        fn=generate_wrapper,
        inputs=[
            prompt, negative_prompt, unet_model, clip_model, vae_model,
            width, height, steps, cfg, sampler, scheduler, seed,
            quantization_dtype,
            lora_1_name, lora_1_strength,
            lora_2_name, lora_2_strength,
            lora_3_name, lora_3_strength,
            lora_4_name, lora_4_strength,
            use_blockswap, blockswap_blocks, blockswap_model_size, blockswap_use_recommended,
            enable_matmul_optimization, use_torch_compile, matmul_precision,
            use_autocast, autocast_dtype, use_channels_last,
            enable_flash_attention, compile_mode, enable_kv_cache
        ],
        outputs=[output_image, output_info]
    )


if __name__ == "__main__":
    # Test UI
    with gr.Blocks() as demo:
        create_qwen_subtab()
    
    demo.launch()
