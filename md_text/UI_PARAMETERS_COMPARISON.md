# UI å‚æ•°å¯¹æ¯”ä¸æ”¹è¿›å»ºè®®

## å½“å‰ UI å‚æ•° vs å·¥ä½œæµå‚æ•°

### âœ… å·²æœ‰å‚æ•°ï¼ˆWanVideoWrapperï¼‰

| å‚æ•° | UI å½“å‰å€¼ | å·¥ä½œæµå€¼ | çŠ¶æ€ |
|------|-----------|----------|------|
| `quantization` | fp4_scaled | fp4_scaled | âœ… å®Œå…¨åŒ¹é… |
| `attention_mode` | sageattn | sageattn_3_fp4 | âš ï¸ é»˜è®¤å€¼ä¸åŒ |
| `base_precision` | fp16_fast | bf16 | âš ï¸ ä¸åŒ |
| `load_device` | offload_device | main_device | âš ï¸ ä¸åŒ |

### âœ… å·²æœ‰å‚æ•°ï¼ˆBlockSwapï¼‰

| å‚æ•° | UI å½“å‰å€¼ | å·¥ä½œæµå€¼ | çŠ¶æ€ |
|------|-----------|----------|------|
| `block_swap_enabled` | false | true | âš ï¸ é»˜è®¤å€¼ä¸åŒ |
| `blocks_to_swap` | 16 | 40 | âš ï¸ é»˜è®¤å€¼ä¸åŒ |

### âŒ ç¼ºå¤±å‚æ•°ï¼ˆWanVideoWrapperï¼‰

| å‚æ•° | å·¥ä½œæµå€¼ | é‡è¦æ€§ | è¯´æ˜ |
|------|----------|--------|------|
| `rms_norm_function` | default | ä¸­ | RMS å½’ä¸€åŒ–å‡½æ•°é€‰æ‹© |

### âŒ ç¼ºå¤±å‚æ•°ï¼ˆBlockSwap/IntelligentVRAMNodeï¼‰

| å‚æ•° | å·¥ä½œæµå€¼ | é‡è¦æ€§ | è¯´æ˜ |
|------|----------|--------|------|
| `enable_cuda_optimization` | true | é«˜ | CUDA ä¼˜åŒ–å¼€å…³ |
| `enable_dram_optimization` | true | é«˜ | DRAM ä¼˜åŒ–å¼€å…³ |
| `auto_hardware_tuning` | false | ä¸­ | è‡ªåŠ¨ç¡¬ä»¶è°ƒä¼˜ |
| `vram_threshold_percent` | 80 | é«˜ | VRAM é˜ˆå€¼ç™¾åˆ†æ¯” |
| `num_cuda_streams` | 16 | é«˜ | CUDA æµæ•°é‡ |
| `bandwidth_target` | 1.0 | ä¸­ | å¸¦å®½ç›®æ ‡ |
| `offload_txt_emb` | false | ä½ | å¸è½½æ–‡æœ¬åµŒå…¥ |
| `offload_img_emb` | false | ä½ | å¸è½½å›¾åƒåµŒå…¥ |
| `vace_blocks_to_swap` | 0 | ä½ | VACE å—äº¤æ¢æ•°é‡ |
| `debug_mode` | false | ä½ | è°ƒè¯•æ¨¡å¼ |

### âŒ ç¼ºå¤±å‚æ•°ï¼ˆWanVideoSamplerï¼‰

| å‚æ•° | å·¥ä½œæµå€¼ | é‡è¦æ€§ | è¯´æ˜ |
|------|----------|--------|------|
| `use_tf32` | false | ä¸­ | ä½¿ç”¨ TF32 |
| `use_cublas_gemm` | false | ä¸­ | ä½¿ç”¨ cuBLAS GEMM |
| `force_contiguous_tensors` | false | ä½ | å¼ºåˆ¶è¿ç»­å¼ é‡ï¼ˆæˆ‘ä»¬çš„ä¿®å¤å·²è¶³å¤Ÿï¼‰ |
| `fuse_qkv_projections` | false | ä½ | èåˆ QKV æŠ•å½± |

## æ¨èçš„ UI æ”¹è¿›

### æ–¹æ¡ˆ 1: æœ€å°æ”¹è¿›ï¼ˆæ¨èï¼‰

**åªæ·»åŠ æœ€å…³é”®çš„å‚æ•°**ï¼Œä¿æŒ UI ç®€æ´ï¼š

#### Optimization Tab å¢å¼º

```python
with gr.Tab("Optimization"):
    with gr.Row():
        with gr.Column():
            gr.Markdown("### Block Swap (IntelligentVRAMNode)")
            block_swap_enabled = gr.Checkbox(label="Enable Block Swap", value=False)
            blocks_to_swap = gr.Slider(0, 48, value=16, step=1, label="Blocks to Swap")
            
            # æ–°å¢ â­
            vram_threshold = gr.Slider(
                30, 90, value=70, step=5, 
                label="VRAM Threshold (%)",
                info="è§¦å‘ BlockSwap çš„ VRAM ä½¿ç”¨ç‡é˜ˆå€¼"
            )
            num_cuda_streams = gr.Slider(
                1, 16, value=8, step=1,
                label="CUDA Streams",
                info="å¹¶å‘ CUDA æµæ•°é‡ï¼ˆè¶Šé«˜è¶Šå¿«ä½†å ç”¨æ›´å¤šèµ„æºï¼‰"
            )
            
            # æ–°å¢ â­
            with gr.Accordion("Advanced BlockSwap", open=False):
                enable_cuda_optimization = gr.Checkbox(
                    label="Enable CUDA Optimization", 
                    value=True,
                    info="å¯ç”¨ CUDA ä¼˜åŒ–ï¼ˆæ¨èï¼‰"
                )
                auto_hardware_tuning = gr.Checkbox(
                    label="Auto Hardware Tuning", 
                    value=False,
                    info="è‡ªåŠ¨æ ¹æ®ç¡¬ä»¶è°ƒæ•´å‚æ•°"
                )
                bandwidth_target = gr.Slider(
                    0.1, 1.0, value=0.8, step=0.1,
                    label="Bandwidth Target",
                    info="å¸¦å®½ç›®æ ‡æ¯”ä¾‹"
                )
```

#### Advanced Settings å¢å¼º

```python
with gr.Column():
    gr.Markdown("### Advanced Settings")
    quantization = gr.Dropdown(
        choices=["disabled", "fp8_scaled", "fp4_scaled", "int8"],
        value="fp4_scaled",
        label="Quantization"
    )
    attention_mode = gr.Dropdown(
        choices=["sageattn", "sageattn_3", "sageattn_3_fp4", "sageattn_3_fp8", "flash_attn", "sdpa", "xformers"],
        value="sageattn_3_fp4",  # æ”¹ä¸º fp4 é»˜è®¤ â­
        label="Attention Mode"
    )
    
    # æ–°å¢ â­
    base_precision = gr.Dropdown(
        choices=["fp16", "bf16", "fp16_fast", "bf16_fast"],
        value="bf16",
        label="Base Precision",
        info="æ¨¡å‹åŸºç¡€ç²¾åº¦"
    )
    load_device = gr.Dropdown(
        choices=["main_device", "offload_device"],
        value="main_device",
        label="Load Device",
        info="æ¨¡å‹åŠ è½½è®¾å¤‡"
    )
    
    # æ–°å¢ â­
    with gr.Accordion("Sampler Advanced", open=False):
        use_tf32 = gr.Checkbox(
            label="Use TF32", 
            value=False,
            info="ä½¿ç”¨ TensorFloat-32ï¼ˆAmpere+ GPUï¼‰"
        )
        use_cublas_gemm = gr.Checkbox(
            label="Use cuBLAS GEMM", 
            value=False,
            info="ä½¿ç”¨ cuBLAS çŸ©é˜µä¹˜æ³•"
        )
```

### æ–¹æ¡ˆ 2: å®Œæ•´æ”¹è¿›ï¼ˆé«˜çº§ç”¨æˆ·ï¼‰

**æ·»åŠ æ‰€æœ‰å‚æ•°**ï¼Œæä¾›å®Œå…¨æ§åˆ¶ï¼š

#### æ–°å¢ "Expert Settings" Tab

```python
with gr.Tab("Expert Settings"):
    gr.Markdown("""
    ### âš ï¸ ä¸“å®¶è®¾ç½®
    è¿™äº›å‚æ•°å¯¹æ€§èƒ½å’Œç¨³å®šæ€§æœ‰é‡å¤§å½±å“ï¼Œè¯·è°¨æ…ä¿®æ”¹ã€‚
    """)
    
    with gr.Row():
        with gr.Column():
            gr.Markdown("### Model Loading")
            base_precision = gr.Dropdown(
                choices=["fp16", "bf16", "fp16_fast", "bf16_fast"],
                value="bf16",
                label="Base Precision"
            )
            load_device = gr.Dropdown(
                choices=["main_device", "offload_device"],
                value="main_device",
                label="Load Device"
            )
            rms_norm_function = gr.Dropdown(
                choices=["default", "fast", "apex"],
                value="default",
                label="RMS Norm Function"
            )
        
        with gr.Column():
            gr.Markdown("### BlockSwap Advanced")
            enable_cuda_optimization = gr.Checkbox(
                label="Enable CUDA Optimization", 
                value=True
            )
            enable_dram_optimization = gr.Checkbox(
                label="Enable DRAM Optimization", 
                value=True
            )
            auto_hardware_tuning = gr.Checkbox(
                label="Auto Hardware Tuning", 
                value=False
            )
            vram_threshold = gr.Slider(
                30, 90, value=70, step=5,
                label="VRAM Threshold (%)"
            )
            num_cuda_streams = gr.Slider(
                1, 16, value=8, step=1,
                label="CUDA Streams"
            )
            bandwidth_target = gr.Slider(
                0.1, 1.0, value=0.8, step=0.1,
                label="Bandwidth Target"
            )
    
    with gr.Row():
        with gr.Column():
            gr.Markdown("### Embedding Offload")
            offload_txt_emb = gr.Checkbox(
                label="Offload Text Embeddings", 
                value=False
            )
            offload_img_emb = gr.Checkbox(
                label="Offload Image Embeddings", 
                value=False
            )
            vace_blocks_to_swap = gr.Slider(
                0, 15, value=0, step=1,
                label="VACE Blocks to Swap"
            )
        
        with gr.Column():
            gr.Markdown("### Sampler Advanced")
            use_tf32 = gr.Checkbox(
                label="Use TF32", 
                value=False
            )
            use_cublas_gemm = gr.Checkbox(
                label="Use cuBLAS GEMM", 
                value=False
            )
            force_contiguous_tensors = gr.Checkbox(
                label="Force Contiguous Tensors", 
                value=False,
                info="å¼ºåˆ¶å¼ é‡è¿ç»­ï¼ˆæˆ‘ä»¬çš„ä¿®å¤å·²è¶³å¤Ÿï¼Œé€šå¸¸ä¸éœ€è¦ï¼‰"
            )
            fuse_qkv_projections = gr.Checkbox(
                label="Fuse QKV Projections", 
                value=False
            )
    
    with gr.Row():
        debug_mode = gr.Checkbox(
            label="Debug Mode", 
            value=False,
            info="å¯ç”¨è¯¦ç»†æ—¥å¿—è¾“å‡º"
        )
```

### æ–¹æ¡ˆ 3: é¢„è®¾é…ç½®ï¼ˆæœ€ç®€å•ï¼‰

**æä¾›é¢„è®¾é…ç½®**ï¼Œç”¨æˆ·åªéœ€é€‰æ‹©åœºæ™¯ï¼š

```python
with gr.Tab("Quick Presets"):
    gr.Markdown("""
    ### ğŸš€ å¿«é€Ÿé¢„è®¾
    æ ¹æ®ä½ çš„ç¡¬ä»¶å’Œéœ€æ±‚é€‰æ‹©é¢„è®¾é…ç½®
    """)
    
    preset = gr.Radio(
        choices=[
            "High Performance (24GB+ VRAM)",
            "Balanced (16GB VRAM)",
            "Memory Efficient (12GB VRAM)",
            "Ultra Low VRAM (8GB VRAM)",
            "Custom"
        ],
        value="Balanced (16GB VRAM)",
        label="Select Preset"
    )
    
    gr.Markdown("""
    **é¢„è®¾è¯´æ˜**ï¼š
    - **High Performance**: æ—  BlockSwapï¼ŒFP4 é‡åŒ–ï¼ŒSage3 FP4 attention
    - **Balanced**: 20 blocks swapï¼ŒFP4 é‡åŒ–ï¼Œ8 CUDA streams
    - **Memory Efficient**: 30 blocks swapï¼ŒFP4 é‡åŒ–ï¼Œ16 CUDA streams
    - **Ultra Low VRAM**: 40 blocks swapï¼ŒFP8 é‡åŒ–ï¼Œ16 CUDA streams
    - **Custom**: æ‰‹åŠ¨é…ç½®æ‰€æœ‰å‚æ•°
    """)
    
    # é¢„è®¾é…ç½®æ˜ å°„
    preset_configs = {
        "High Performance (24GB+ VRAM)": {
            "quantization": "fp4_scaled",
            "attention_mode": "sageattn_3_fp4",
            "blocks_to_swap": 0,
            "num_cuda_streams": 8,
            "vram_threshold": 90
        },
        "Balanced (16GB VRAM)": {
            "quantization": "fp4_scaled",
            "attention_mode": "sageattn_3_fp4",
            "blocks_to_swap": 20,
            "num_cuda_streams": 8,
            "vram_threshold": 70
        },
        "Memory Efficient (12GB VRAM)": {
            "quantization": "fp4_scaled",
            "attention_mode": "sageattn_3_fp4",
            "blocks_to_swap": 30,
            "num_cuda_streams": 16,
            "vram_threshold": 60
        },
        "Ultra Low VRAM (8GB VRAM)": {
            "quantization": "fp8_scaled",
            "attention_mode": "sageattn_3_fp8",
            "blocks_to_swap": 40,
            "num_cuda_streams": 16,
            "vram_threshold": 50
        }
    }
```

## æ¨èå®æ–½æ–¹æ¡ˆ

### é˜¶æ®µ 1: ç«‹å³æ”¹è¿›ï¼ˆæ–¹æ¡ˆ 1ï¼‰

**ä¼˜å…ˆçº§é«˜çš„å‚æ•°**ï¼š
1. âœ… `vram_threshold` - VRAM é˜ˆå€¼
2. âœ… `num_cuda_streams` - CUDA æµæ•°é‡
3. âœ… `base_precision` - åŸºç¡€ç²¾åº¦
4. âœ… `load_device` - åŠ è½½è®¾å¤‡
5. âœ… ä¿®æ”¹ `attention_mode` é»˜è®¤å€¼ä¸º `sageattn_3_fp4`

**é¢„è®¡å·¥ä½œé‡**ï¼š30 åˆ†é’Ÿ

### é˜¶æ®µ 2: å®Œæ•´æ”¹è¿›ï¼ˆæ–¹æ¡ˆ 2ï¼‰

**æ·»åŠ æ‰€æœ‰å‚æ•°**ï¼Œæä¾›å®Œå…¨æ§åˆ¶ã€‚

**é¢„è®¡å·¥ä½œé‡**ï¼š1-2 å°æ—¶

### é˜¶æ®µ 3: ç”¨æˆ·å‹å¥½ï¼ˆæ–¹æ¡ˆ 3ï¼‰

**æ·»åŠ é¢„è®¾é…ç½®**ï¼Œç®€åŒ–ç”¨æˆ·é€‰æ‹©ã€‚

**é¢„è®¡å·¥ä½œé‡**ï¼š1 å°æ—¶

## å½“å‰ UI çš„ä¸»è¦é—®é¢˜

### 1. é»˜è®¤å€¼ä¸åŒ¹é…å·¥ä½œæµ

| å‚æ•° | UI é»˜è®¤ | å·¥ä½œæµ | å»ºè®® |
|------|---------|--------|------|
| `attention_mode` | sageattn | sageattn_3_fp4 | æ”¹ä¸º sageattn_3_fp4 |
| `blocks_to_swap` | 16 | 40 | ä¿æŒ 16ï¼ˆæ›´å®‰å…¨ï¼‰ |
| `block_swap_enabled` | false | true | ä¿æŒ falseï¼ˆé»˜è®¤ä¸å¯ç”¨ï¼‰ |

### 2. ç¼ºå°‘å…³é”®å‚æ•°

- âŒ `vram_threshold` - æ— æ³•æ§åˆ¶ä½•æ—¶è§¦å‘ BlockSwap
- âŒ `num_cuda_streams` - æ— æ³•ä¼˜åŒ–å¹¶å‘æ€§èƒ½
- âŒ `base_precision` - æ— æ³•é€‰æ‹©ç²¾åº¦
- âŒ `load_device` - æ— æ³•é€‰æ‹©åŠ è½½è®¾å¤‡

### 3. æ²¡æœ‰é¢„è®¾é…ç½®

ç”¨æˆ·éœ€è¦æ‰‹åŠ¨é…ç½®å¤šä¸ªå‚æ•°ï¼Œå®¹æ˜“å‡ºé”™ã€‚

## å»ºè®®çš„ä»£ç ä¿®æ”¹

### ä¿®æ”¹ 1: æ›´æ–°é»˜è®¤å€¼

```python
# æ–‡ä»¶: wanvideo_gradio_app.py, è¡Œ 702-706

attention_mode = gr.Dropdown(
    choices=["sageattn", "sageattn_3", "sageattn_3_fp4", "sageattn_3_fp8", "flash_attn", "sdpa", "xformers"],
    value="sageattn_3_fp4",  # â­ æ”¹ä¸º fp4
    label="Attention Mode",
    info="æ¨èä½¿ç”¨ sageattn_3_fp4 ä»¥è·å¾—æœ€ä½³æ€§èƒ½"
)
```

### ä¿®æ”¹ 2: æ·»åŠ å…³é”®å‚æ•°

```python
# æ–‡ä»¶: wanvideo_gradio_app.py, è¡Œ 740-743

with gr.Column():
    gr.Markdown("### Block Swap")
    block_swap_enabled = gr.Checkbox(label="Enable Block Swap", value=False)
    blocks_to_swap = gr.Slider(0, 48, value=16, step=1, label="Blocks to Swap")
    
    # â­ æ–°å¢
    vram_threshold = gr.Slider(
        30, 90, value=70, step=5,
        label="VRAM Threshold (%)",
        info="å½“ VRAM ä½¿ç”¨ç‡è¶…è¿‡æ­¤å€¼æ—¶è§¦å‘ BlockSwap"
    )
    num_cuda_streams = gr.Slider(
        1, 16, value=8, step=1,
        label="CUDA Streams",
        info="å¹¶å‘ CUDA æµæ•°é‡ï¼ˆRTX 4090/5090 æ¨è 16ï¼‰"
    )
```

### ä¿®æ”¹ 3: æ›´æ–°å‡½æ•°ç­¾å

```python
# æ–‡ä»¶: wanvideo_gradio_app.py, è¡Œ 159-174

def generate_video(
    self,
    # ... å…¶ä»–å‚æ•° ...
    quantization: str,
    attention_mode: str,
    # â­ æ–°å¢
    base_precision: str,
    load_device: str,
    # LoRA parameters
    lora_enabled: bool,
    lora_name: str,
    lora_strength: float,
    # Optimization parameters
    compile_enabled: bool,
    compile_backend: str,
    block_swap_enabled: bool,
    blocks_to_swap: int,
    # â­ æ–°å¢
    vram_threshold: float,
    num_cuda_streams: int,
    enable_cuda_optimization: bool,
    # Output parameters
    output_format: str,
    fps: int,
    progress_callback=None
):
```

## æ€»ç»“

### å½“å‰çŠ¶æ€

- âœ… åŸºç¡€å‚æ•°å·²æš´éœ²ï¼ˆquantization, attention_mode, blocks_to_swapï¼‰
- âš ï¸ é»˜è®¤å€¼ä¸åŒ¹é…å·¥ä½œæµ
- âŒ ç¼ºå°‘å…³é”® BlockSwap å‚æ•°
- âŒ ç¼ºå°‘æ¨¡å‹åŠ è½½å‚æ•°
- âŒ æ²¡æœ‰é¢„è®¾é…ç½®

### æ¨èè¡ŒåŠ¨

1. **ç«‹å³ä¿®æ”¹**ï¼šæ›´æ–° `attention_mode` é»˜è®¤å€¼ä¸º `sageattn_3_fp4`
2. **çŸ­æœŸæ·»åŠ **ï¼š`vram_threshold` å’Œ `num_cuda_streams`ï¼ˆæ–¹æ¡ˆ 1ï¼‰
3. **ä¸­æœŸæ”¹è¿›**ï¼šæ·»åŠ æ‰€æœ‰ä¸“å®¶å‚æ•°ï¼ˆæ–¹æ¡ˆ 2ï¼‰
4. **é•¿æœŸä¼˜åŒ–**ï¼šæ·»åŠ é¢„è®¾é…ç½®ï¼ˆæ–¹æ¡ˆ 3ï¼‰

è¿™æ ·ç”¨æˆ·å°±èƒ½å®Œå…¨æ§åˆ¶æ‰€æœ‰å‚æ•°ï¼ŒåŒæ—¶ä¿æŒ UI çš„æ˜“ç”¨æ€§ï¼
